method: "inference_timm_xgboost" # New method identifier
num_channels: 3 # Most TIMM models expect 3 channels

# Class names for dynamic loading
detector_class_name: "src.eddy_detector.timm_xgboost_detector.TimmXGBoostEddyDetector"

# Dataset parameters (nested under a single key)
dataset_params:
  dataset_class_name: "src.dataset.SARTileDataset"
  geotiff_dir: "data/"
  preprocessed_dir: "data/"
  land_shapefile: "data/land_mask/ne_10m_land.shp"
  window_size: 700
  stride_factor: 0.25
  nodata_threshold: 0.5
  var_threshold: 1.0e-5

# Model options
# arch: "convnext_base.clip_laion2b_augreg" # Specify TIMM model from the script
arch: "eva02_large_patch14_448.mim_in22k_ft_in22k" # Specify TIMM model from the script
model_loader_class: "src.models.timm_loader.TimmLoader"
# 'pretrain' for SimCLR model is not used here. TIMM handles its own pretraining.
# pipeline_path: "/home1/07265/egoh/work/SLICE/sar_eddy_validation/models/best_pipeline_convnext_base.clip_laion2b_augreg_57336rows_classifier__colsample_bytree_0.8_classifier__gamma_0.2_classifier__learning_rate_0.15_classifier__max_depth_4_classifier__n_estimators_450_classifier__subsample_0.75.pkl" # Path to the saved scikit-learn pipeline
# pipeline_path: "/home1/07265/egoh/work/SLICE/sar_eddy_validation/models/pipeline_eva02_large_patch14_448.mim_in22k_ft_in22k_57336rows_classifier__colsample_bytree_0.5_classifier__gamma_0.1_classifier__learning_rate_0.05_classifier__max_depth_7_classifier__n_estimators_600_classifier__subsample_0.9.pkl"
pipeline_path: "model_checkpoints/eva02_large_patch14_448.mim_in22k_ft_in22k_xgboost_pipeline.pkl"
num_classes: 2 # As defined by the saved pipeline's output
nodata_value: 0

# Inference options
batch_size: 128 # Adjust based on GPU memory for TIMM model
# output_dir: "/scratch/07265/egoh/output_timm_xgboost_all_optimized_model_eva02_large" # Separate output directory
# output_dir: "/scratch/07265/egoh/output_ben_test_20190105/jp2"
# identification_table_path: "/scratch/07265/egoh/output_ben_test_20190105/jp2/positive_eddy_identifications.csv"
output_dir: "output/timm_xgboost"
identification_table_path: "output/timm_xgboost/positive_eddy_identifications.csv"
positive_class_index: 1 # Assuming 1 still means eddy in the saved pipeline
workers: 8 # Keep or adjust based on system
device: "cuda" # Use GPU if available, fallback handled in code

# Prefilter configuration (Keep as is, likely not used for this specific workflow)
prefilter:
  enabled: false
  store_results: false
  pass_classes: [2]
  model:
    arch: "r50_1x_sk0"
    num_classes: 10
    pretrain: null